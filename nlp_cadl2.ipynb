{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kt608iR0lpJr",
        "outputId": "fc595067-91f4-4639-f14a-a84dbffc0d40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Dataset (Corpus):\n",
            "1. I loved the movie! It was fantastic and thrilling.\n",
            "2. The film was terrible, I hated every moment of it.\n",
            "3. What a great experience, the actors did a wonderful job.\n",
            "4. I would not recommend this movie to anyone.\n",
            "5. An excellent and inspiring story, truly enjoyed it!\n",
            "\n",
            "Preprocessed Corpus:\n",
            "1. loved movie fantastic thrilling\n",
            "2. film terrible hated every moment\n",
            "3. great experience actors wonderful job\n",
            "4. would recommend movie anyone\n",
            "5. excellent inspiring story truly enjoyed\n",
            "\n",
            "Bag-of-Words Vocabulary:\n",
            "['actors' 'anyone' 'enjoyed' 'every' 'excellent' 'experience' 'fantastic'\n",
            " 'film' 'great' 'hated' 'inspiring' 'job' 'loved' 'moment' 'movie'\n",
            " 'recommend' 'story' 'terrible' 'thrilling' 'truly' 'wonderful' 'would']\n",
            "\n",
            "Bag-of-Words Representation (Document-Term Matrix):\n",
            "[[0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0]\n",
            " [0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 0]\n",
            " [1 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0]\n",
            " [0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1]\n",
            " [0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0]]\n",
            "\n",
            "TF-IDF Vocabulary:\n",
            "['actors' 'anyone' 'enjoyed' 'every' 'excellent' 'experience' 'fantastic'\n",
            " 'film' 'great' 'hated' 'inspiring' 'job' 'loved' 'moment' 'movie'\n",
            " 'recommend' 'story' 'terrible' 'thrilling' 'truly' 'wonderful' 'would']\n",
            "\n",
            "TF-IDF Representation (Document-Term Matrix):\n",
            "[[0.         0.         0.         0.         0.         0.\n",
            "  0.52335825 0.         0.         0.         0.         0.\n",
            "  0.52335825 0.         0.42224214 0.         0.         0.\n",
            "  0.52335825 0.         0.         0.        ]\n",
            " [0.         0.         0.         0.4472136  0.         0.\n",
            "  0.         0.4472136  0.         0.4472136  0.         0.\n",
            "  0.         0.4472136  0.         0.         0.         0.4472136\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.4472136  0.         0.         0.         0.         0.4472136\n",
            "  0.         0.         0.4472136  0.         0.         0.4472136\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.4472136  0.        ]\n",
            " [0.         0.52335825 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.42224214 0.52335825 0.         0.\n",
            "  0.         0.         0.         0.52335825]\n",
            " [0.         0.         0.4472136  0.         0.4472136  0.\n",
            "  0.         0.         0.         0.         0.4472136  0.\n",
            "  0.         0.         0.         0.         0.4472136  0.\n",
            "  0.         0.4472136  0.         0.        ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install nltk scikit-learn\n",
        "\n",
        "import nltk\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "corpus = [\n",
        "    \"I loved the movie! It was fantastic and thrilling.\",\n",
        "    \"The film was terrible, I hated every moment of it.\",\n",
        "    \"What a great experience, the actors did a wonderful job.\",\n",
        "    \"I would not recommend this movie to anyone.\",\n",
        "    \"An excellent and inspiring story, truly enjoyed it!\"\n",
        "]\n",
        "\n",
        "print(\"Original Dataset (Corpus):\")\n",
        "for i, doc in enumerate(corpus, 1):\n",
        "    print(f\"{i}. {doc}\")\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import string\n",
        "\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "\n",
        "def preprocess(text):\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    tokens = [w for w in tokens if w.isalpha() and w not in stop_words]\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "processed_corpus = [preprocess(doc) for doc in corpus]\n",
        "\n",
        "print(\"\\nPreprocessed Corpus:\")\n",
        "for i, doc in enumerate(processed_corpus, 1):\n",
        "    print(f\"{i}. {doc}\")\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "bow_vectorizer = CountVectorizer()\n",
        "bow_matrix = bow_vectorizer.fit_transform(processed_corpus)\n",
        "\n",
        "print(\"\\nBag-of-Words Vocabulary:\")\n",
        "print(bow_vectorizer.get_feature_names_out())\n",
        "\n",
        "print(\"\\nBag-of-Words Representation (Document-Term Matrix):\")\n",
        "print(bow_matrix.toarray())\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(processed_corpus)\n",
        "\n",
        "print(\"\\nTF-IDF Vocabulary:\")\n",
        "print(tfidf_vectorizer.get_feature_names_out())\n",
        "\n",
        "print(\"\\nTF-IDF Representation (Document-Term Matrix):\")\n",
        "print(tfidf_matrix.toarray())\n"
      ]
    }
  ]
}